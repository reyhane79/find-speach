{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Pitch Contour\n",
    "In this project, we will process the following sentence spoken in both English and Persian:\n",
    "\n",
    "\"In many examples that we discuss in this book, it is necessary to change the sampling rate of a discrete-time signal.\" \n",
    "\"در بسیاری از مثال‌هایی که در این کتاب به آن‌ها پرداخته‌ایم، تغییر نرخ نمونه‌برداری از یک سیگنال زمان گسسته ضروری است.\"\n",
    "(page 47, line5)\n",
    "The English voice is stored in a file named `voice-en.mp3` and the Persian voice is in `voice-fa.mp3`.\n",
    "\n",
    "Our goal is to obtain the pitch contour of these voice signals using three different methods:\n",
    "1. Average Magnitude Difference Function (AMDF)\n",
    "2. Autocorrelation\n",
    "3. Cepstrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Audio Files\n",
    "First, we need to load the audio files. We'll use the `librosa` library for this. `librosa` is a Python library for music and audio analysis. It provides the building blocks necessary to create music information retrieval systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Loading the audio files\n",
    "\n",
    "# English voice\n",
    "audio_file_en = 'voice-en.mp3'\n",
    "signal_en, sr_en = librosa.load(audio_file_en, sr=None)  # sr=None to preserve the original sampling rate\n",
    "\n",
    "# Persian voice\n",
    "audio_file_fa = 'voice-fa.mp3'\n",
    "signal_fa, sr_fa = librosa.load(audio_file_fa, sr=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Pitch Contour using AMDF\n",
    "Next, we'll extract the pitch contour using the Average Magnitude Difference Function (AMDF). The AMDF is a simple, efficient method of pitch detection, which works particularly well for high-quality, low-noise audio signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Implementing pitch detection methods\n",
    "\n",
    "# We'll start with the AMDF method\n",
    "def compute_amdf(signal, frame_size):\n",
    "    # Initialize the array to hold the AMDF values\n",
    "    amdf_values = np.zeros(frame_size)\n",
    "\n",
    "    # Loop over each possible lag (up to frame size)\n",
    "    for lag in range(frame_size):\n",
    "        # Calculate the AMDF for this lag\n",
    "        amdf_values[lag] = np.mean(np.abs(signal[:-lag or None] - signal[lag:]))\n",
    "\n",
    "    return amdf_values\n",
    "\n",
    "# Apply the AMDF method to a frame of the Persian voice signal\n",
    "frame_size = 2048  # Choose an appropriate frame size based on your signal\n",
    "frame_fa = signal_fa[:frame_size]\n",
    "amdf_values_fa = compute_amdf(frame_fa, frame_size)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.plot(amdf_values_fa)\n",
    "plt.title('AMDF Pitch Contour - Persian Voice')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('AMDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Pitch Contour using Autocorrelation\n",
    "Next, we'll extract the pitch contour using the Autocorrelation method. Autocorrelation is a mathematical tool for finding repeating patterns, such as the presence of a periodic signal obscured by noise, or identifying the missing fundamental frequency in a signal implied by its harmonic frequencies.\n",
    "\n",
    "The Autocorrelation method is a widely used approach for pitch detection. The basic idea is to compute the correlation of the signal with a delayed version of itself. The delay which maximizes this correlation corresponds to the period of the pitch, and thus the pitch can be calculated as the inverse of this period.\n",
    "\n",
    "The code for the Autocorrelation method is very similar to the AMDF method. The main difference is the computation inside the loop: instead of computing the mean difference, we compute the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_autocorrelation(signal, frame_size):\n",
    "    # Initialize the array to hold the autocorrelation values\n",
    "    autocorr_values = np.zeros(frame_size)\n",
    "\n",
    "    # Loop over each possible lag (up to frame size)\n",
    "    for lag in range(frame_size):\n",
    "        # Calculate the autocorrelation for this lag\n",
    "        autocorr_values[lag] = np.correlate(signal[:-lag or None], signal[lag:])\n",
    "\n",
    "    return autocorr_values\n",
    "\n",
    "# Apply the Autocorrelation method to a frame of the Persian voice signal\n",
    "frame_fa = signal_fa[:frame_size]\n",
    "autocorr_values_fa = compute_autocorrelation(frame_fa, frame_size)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.plot(autocorr_values_fa)\n",
    "plt.title('Autocorrelation Pitch Contour - Persian Voice')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Pitch Contour using Cepstrum\n",
    "The Cepstrum method is a more complex approach.\n",
    "\n",
    "1. Compute the Fourier Transform of the signal.\n",
    "2. Take the logarithm of the magnitude of the Fourier Transform. This process is equivalent to converting the spectrum from a power scale to a decibel scale.\n",
    "3. Compute the inverse Fourier Transform of the result from step 2. The result of this step is called the cepstrum.\n",
    "4. The pitch can be found as the delay (in samples) corresponding to the peak in the cepstrum.\n",
    "\n",
    "In the code above, the `np.fft.fft` function is used to compute the Fourier Transform, `np.log1p` is used to compute the logarithm of the magnitude spectrum (the `1p` in `log1p` stands for \"plus 1\", which helps avoid taking the logarithm of zero), and `np.fft.ifft` is used to compute the inverse Fourier Transform.\n",
    "\n",
    "The Cepstrum method should give us another perspective on the pitch contour of the signals. After we've computed the pitch contours for both signals using all three methods, we can start analyzing the results and comparing the methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cepstrum(signal, frame_size):\n",
    "    # Compute the Fourier Transform of the signal\n",
    "    spectrum = np.fft.fft(signal, n=frame_size)\n",
    "\n",
    "    # Compute the log magnitude of the spectrum\n",
    "    log_magnitude_spectrum = np.log1p(np.abs(spectrum))\n",
    "\n",
    "    # Compute the inverse Fourier Transform of the log magnitude spectrum\n",
    "    cepstrum = np.fft.ifft(log_magnitude_spectrum)\n",
    "\n",
    "    return np.abs(cepstrum)\n",
    "\n",
    "# Apply the Cepstrum method to a frame of the Persian voice signal\n",
    "frame_fa = signal_fa[:frame_size]\n",
    "cepstrum_values_fa = compute_cepstrum(frame_fa, frame_size)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.plot(cepstrum_values_fa)\n",
    "plt.title('Cepstrum Pitch Contour - Persian Voice')\n",
    "plt.xlabel('Quefrency')\n",
    "plt.ylabel('Cepstrum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
